{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SPARSE_FEATURES': ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26'], 'DENSE_FEATURES': ['I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11', 'I12', 'I13'], 'label': ['label']}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "sys.path.append(\"../data/\")\n",
    "from dataconfig import *\n",
    "from utils import *\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spase_feature_names = DATA_CONFIG['SPARSE_FEATURES']\n",
    "dense_feature_names = DATA_CONFIG['DENSE_FEATURES']\n",
    "label_feature_names = DATA_CONFIG['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "if platform.system() != 'Windows':\n",
    "    dataset = DataUtil(spase_feature_names, dense_feature_names, label_feature_names).read_tfrecord(\"../data/tf_data/train_criteo_5w_rows.tfrecord\", 512)\n",
    "    eval_data = DataUtil(spase_feature_names, dense_feature_names, label_feature_names).read_tfrecord(\"../data/tf_data/test_criteo_1w_rows.tfrecord\", 512)\n",
    "    valid_data = DataUtil(spase_feature_names, dense_feature_names, label_feature_names).read_tfrecord(\"../data/tf_data/valid_criteo_1w_rows.tfrecord\", 512)\n",
    "else:\n",
    "    dataset = DataUtil(spase_feature_names, dense_feature_names, label_feature_names).read_tfrecord(\"../data/tf_data/train_criteo_200w_rows.tfrecord\", 512)\n",
    "    eval_data = DataUtil(spase_feature_names, dense_feature_names, label_feature_names).read_tfrecord(\"../data/tf_data/test_criteo_20w_rows.tfrecord\", 512)\n",
    "    valid_data = DataUtil(spase_feature_names, dense_feature_names, label_feature_names).read_tfrecord(\"../data/tf_data/valid_criteo_20w_rows.tfrecord\", 512)\n",
    "\n",
    "# 定义 inputs\n",
    "\n",
    "inputs = { name:keras.Input(shape=(1,), name=name, dtype=tf.float32) for name in dense_feature_names }\n",
    "inputs.update({\n",
    "    name:keras.Input(shape=(1,), name=name, dtype=tf.string) for name in spase_feature_names\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import Model \n",
    "import tensorflow as tf \n",
    "import tensorflow.keras as layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(Layer):\n",
    "    # test_x = tf.random.uniform(shape=(32, 8, 8))\n",
    "    # fm_test = FM()\n",
    "    # fm_test(test_x)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def call(self, X):\n",
    "        # a + b \n",
    "        sum_squre = tf.square( tf.reduce_sum(X, axis = 1))\n",
    "        squre_sum = tf.reduce_sum(tf.square(X), axis = 1)\n",
    "\n",
    "        return 0.5 * tf.reduce_sum(sum_squre - squre_sum, axis = 1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6931472>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1412084083.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 13\u001b[1;36m\u001b[0m\n\u001b[1;33m    def\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class DNN(Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.dnn = keras.Sequential([])\n",
    "\n",
    "        for unit in units:\n",
    "            self.dnn.add( keras.layers.Dense(unit,  activation='relu') )\n",
    "    def call(self, X):\n",
    "        return self.dnn(X)\n",
    "\n",
    "class DataProcess(Layer):\n",
    "    def __init__(self, inputs, dense_features):\n",
    "        self.dense_features = dense_features\n",
    "        self.concat = layers.Concatenate()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        dense_res = [] \n",
    "        \n",
    "        for name, v in inputs:\n",
    "            if name in dense_features:\n",
    "                temp = tf.floor( tf.math.log1p(v) / tf.math.log(tf.constant(2.0, dtype=tf.float32)) )\n",
    "                dense_res.append(temp)\n",
    "        return self.concat(dense_res)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "class deepFM(Model):\n",
    "    def __init__(self, inputs, sparse_features, dense_features, units, if_fm = True):\n",
    "\n",
    "        sparse_features_hashing = {}\n",
    "        sparse_features_embeddings = {}\n",
    "\n",
    "        self.sparse_features = sparse_features\n",
    "        self.dense_features = dense_features\n",
    "        num_bins = 1000000\n",
    "\n",
    "        self.dense_feature_layer = DataProcess(inputs, dense_features)\n",
    "        for name, v in inputs:\n",
    "            if name in sparse_features:\n",
    "                sparse_features_hashing[name] = keras.layers.Hashing(num_bins, mask_value='')\n",
    "                sparse_features_embeddings[name] = keras.layers.Embedding(num_bins,8 , mask_zero=True)\n",
    "\n",
    "        self.concat = layers.Concatenate()\n",
    "        self.dnn = DNN(units)\n",
    "        self.out_layer = Dense(1)\n",
    "        if is_fm:\n",
    "            self.fm = FM()\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        dense_res = self.dense_feature_layer(inputs)\n",
    "\n",
    "        embeddings = []\n",
    "        for name, v in inputs.items():\n",
    "            if name in self.sparse_features:\n",
    "                x = self.sparse_features_hashing[name](v)\n",
    "                x = self.sparse_features_embeddings[name](x)\n",
    "                embeddings.append(x)\n",
    "\n",
    "        all_features_concat = self.concat(embeddings + [dense_res])\n",
    "        \n",
    "        logit = 0\n",
    "        if self.is_fm:\n",
    "            logit += self.fm(embeddings)\n",
    "        logit += self.out_layer(self.dnn(all_features_concat))\n",
    "        \n",
    "        return logit\n",
    "        \n",
    "\n",
    "    def plot_model_in_class(self, inputs):\n",
    "\n",
    "        # 获取模型的结构\n",
    "        x = self.call(inputs)  # 调用 call 方法\n",
    "\n",
    "        # 构建一个新的 Keras 模型，用于绘制图形\n",
    "        model_for_plot = keras.Model(inputs, x)\n",
    "        \n",
    "        # 绘制模型\n",
    "        tf.keras.utils.plot_model(\n",
    "            model_for_plot, \n",
    "            to_file=\"custom_model2_plot.png\",  # 可指定文件路径\n",
    "            show_shapes=True, \n",
    "            show_layer_names=True,\n",
    "            rankdir='LR',  # Left to Right 排列\n",
    "            dpi=75\n",
    "        )\n",
    "        print(\"Model plot saved as custom_model2_plot.png\")\n",
    "\n",
    "    def predict_test_data(eval_data):\n",
    "        auc = tf.metrics.AUC()\n",
    "        for batch in eval_data:\n",
    "            label = eval_data.pop('label')\n",
    "            pred = self(batch)\n",
    "            label = tf.expand_dims(label, 1) \n",
    "            \n",
    "            auc.update_state(label, y_pred=pred)\n",
    "            \n",
    "\n",
    "        return auc.result().numpy()\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "\n",
    "        train_data, label = inputs\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = self(inputs)\n",
    "            loss = tf.reduce_mean(self.loss(label, pred))\n",
    "            \n",
    "        \n",
    "        train_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, train_vars)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(gradients, train_vars))\n",
    "        self.compiled_metrics.update_state(label, pred)\n",
    "\n",
    "        results = {m.name : m.result() for m in self.metrics}\n",
    "        return results\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
