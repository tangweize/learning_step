{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae4c742-e9dd-42b9-849a-7249e91c3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from models.model import *\n",
    "from ltv_utils import *\n",
    "from losses.custom_loss import *\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)  # 保留10位小数，可调整\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_function(serialized_example):\n",
    "    feature_description = {\n",
    "        'deviceid': tf.io.FixedLenFeature([], tf.string),\n",
    "        'install_date': tf.io.FixedLenFeature([], tf.string),\n",
    "        'dim_os_name1': tf.io.FixedLenFeature([], tf.string),\n",
    "        'creative_classify1': tf.io.FixedLenFeature([], tf.string),\n",
    "        'total_pay_amount1':  tf.io.FixedLenFeature([], tf.float32),\n",
    "         'channel1': tf.io.FixedLenFeature([], tf.string),\n",
    "        'b2_sale_amt_bias':  tf.io.FixedLenFeature([], tf.int64),\n",
    "         'b2_sale_amt_7d': tf.io.FixedLenFeature([], tf.int64),\n",
    "         'install_time': tf.io.FixedLenFeature([], tf.string),\n",
    "        'install_order_diff':  tf.io.FixedLenFeature([], tf.int64),\n",
    "        'all_install_order_7d_diff':  tf.io.FixedLenFeature([], tf.int64),\n",
    "        'is_a1x_a33':  tf.io.FixedLenFeature([], tf.int64),\n",
    "        'platform_label':  tf.io.FixedLenFeature([], tf.string),\n",
    "        'user_dense_price_features': tf.io.FixedLenFeature([len(group_2_features['user_dense_price_features'])], tf.float32),\n",
    "        'user_dense_duration_features': tf.io.FixedLenFeature([len(group_2_features['user_dense_duration_features'])], tf.float32),\n",
    "        'user_dense_features': tf.io.FixedLenFeature([len(group_2_features['user_dense_features'])], tf.float32),\n",
    "        'user_sparse_features': tf.io.FixedLenFeature([len(group_2_features['user_sparse_features'])], tf.float32)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "    return example\n",
    "\n",
    "\n",
    "# load tf records\n",
    "group_2_features = read_feature_json_config('features/feature_list.json')\n",
    "file_name = 'data/loca_test_tf.tfrecords'\n",
    "data_path = file_name\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(data_path)\n",
    "dataset = dataset.map(parse_function)\n",
    "\n",
    "dataset = dataset.prefetch(buffer_size=10000)\n",
    "dataset = dataset.batch(512)\n",
    "\n",
    "user_dense_price_features = group_2_features['user_dense_price_features']\n",
    "user_dense_duration_features = group_2_features['user_dense_duration_features']\n",
    "user_dense_features = group_2_features['user_dense_features']\n",
    "user_sparse_features = group_2_features['user_sparse_features']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea4a202-5a4b-4e9d-af5e-3ebbaaca6688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(dataset):\n",
    "    sample_batch = next(iter(dataset))\n",
    "    sample_data = {k: v for k, v in sample_batch.items() if k not in ['b2_sale_amt_7d', 'total_pay_amount1']}\n",
    "\n",
    "    def generator():\n",
    "        for batch in dataset:\n",
    "            b2_7d = tf.cast(tf.reshape(batch.pop('b2_sale_amt_7d'), (-1, 1)), tf.float32)\n",
    "            total_amt_1h = tf.reshape(batch.pop('total_pay_amount1'), (-1, 1))\n",
    "            y_true_packed = tf.concat([b2_7d, total_amt_1h], axis=1)\n",
    "            yield batch, y_true_packed\n",
    "\n",
    "    # 正确写法：output_signature 中保留每个字段的真实 shape\n",
    "    output_signature = (\n",
    "        {\n",
    "            name: tf.TensorSpec(shape=(None,) + v.shape[1:], dtype=v.dtype)\n",
    "            for name, v in sample_data.items()\n",
    "        },\n",
    "        tf.TensorSpec(shape=(None, 2), dtype=tf.float32)\n",
    "    )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(generator, output_signature=output_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e09ed739-cf97-4af7-957e-bc0fa616a72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 18:02:06.910420: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "emb_features = [\n",
    "'creative_classify','dim_device_manufacture', 'car_add_type_most','show_order_is_2arrival_latest', 'selecttirecount_most', 'show_order_is_2arrival_most','selecttirecount_latest',\n",
    " 'new_sitename','advsite','car_add_type_latest','platform_level', 'tire_list_click_avg_index','tire_list_click_most_pid_level','tire_order_page_most_pid_level',\n",
    "]\n",
    "\n",
    "\n",
    "model = MULTI_HEAD_LTV_MODEL(5, [200,200], [200,128], 'user_dense_features', 'user_dense_price_features', 'user_dense_duration_features',\n",
    "                            'user_sparse_features',user_sparse_features, emb_features)\n",
    "\n",
    "\n",
    "sample = next(iter(dataset))\n",
    "input_shape = {k: v.shape for k, v in sample.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "587895c8-7cab-43fd-aed6-d7e6e2d9ef58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_install_order_7d_diff': TensorShape([512]),\n",
       " 'b2_sale_amt_7d': TensorShape([512]),\n",
       " 'b2_sale_amt_bias': TensorShape([512]),\n",
       " 'channel1': TensorShape([512]),\n",
       " 'creative_classify1': TensorShape([512]),\n",
       " 'deviceid': TensorShape([512]),\n",
       " 'dim_os_name1': TensorShape([512]),\n",
       " 'install_date': TensorShape([512]),\n",
       " 'install_order_diff': TensorShape([512]),\n",
       " 'install_time': TensorShape([512]),\n",
       " 'is_a1x_a33': TensorShape([512]),\n",
       " 'platform_label': TensorShape([512]),\n",
       " 'total_pay_amount1': TensorShape([512]),\n",
       " 'user_dense_duration_features': TensorShape([512, 6]),\n",
       " 'user_dense_features': TensorShape([512, 83]),\n",
       " 'user_dense_price_features': TensorShape([512, 9]),\n",
       " 'user_sparse_features': TensorShape([512, 22])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff9140f1-00ac-431c-b1ca-ea72c0725eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 19:02:53.675440: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2025-06-19 19:02:53.675457: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2025-06-19 19:02:53.675657: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"multi_head_ltv_model/ExpandDims:0\", shape=(None, 1), dtype=float32)\n",
      "Tensor(\"multi_head_ltv_model/ExpandDims:0\", shape=(None, 1), dtype=float32)\n",
      "      9/Unknown - 2s 14ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 19:02:55.772774: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2025-06-19 19:02:55.772788: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2025-06-19 19:02:56.674875: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2025-06-19 19:02:56.742878: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2025-06-19 19:02:56.798394: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20250619-190253/plugins/profile/2025_06_19_19_02_56\n",
      "\n",
      "2025-06-19 19:02:56.862695: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/fit/20250619-190253/plugins/profile/2025_06_19_19_02_56/CK-L220022-2.local.trace.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     27/Unknown - 3s 51ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 19:02:56.879033: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/20250619-190253/plugins/profile/2025_06_19_19_02_56\n",
      "\n",
      "2025-06-19 19:02:56.879270: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/20250619-190253/plugins/profile/2025_06_19_19_02_56/CK-L220022-2.local.memory_profile.json.gz\n",
      "2025-06-19 19:02:56.880243: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/fit/20250619-190253/plugins/profile/2025_06_19_19_02_56\n",
      "Dumped tool data for xplane.pb to logs/fit/20250619-190253/plugins/profile/2025_06_19_19_02_56/CK-L220022-2.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/20250619-190253/plugins/profile/2025_06_19_19_02_56/CK-L220022-2.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/20250619-190253/plugins/profile/2025_06_19_19_02_56/CK-L220022-2.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/20250619-190253/plugins/profile/2025_06_19_19_02_56/CK-L220022-2.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/20250619-190253/plugins/profile/2025_06_19_19_02_56/CK-L220022-2.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 7s 13ms/step\n",
      "Epoch 2/10\n",
      "346/346 [==============================] - 3s 9ms/step\n",
      "Epoch 3/10\n",
      "346/346 [==============================] - 3s 9ms/step\n",
      "Epoch 4/10\n",
      "346/346 [==============================] - 3s 9ms/step\n",
      "Epoch 5/10\n",
      "346/346 [==============================] - 3s 9ms/step\n",
      "Epoch 6/10\n",
      "346/346 [==============================] - 3s 10ms/step\n",
      "Epoch 7/10\n",
      "346/346 [==============================] - 3s 10ms/step\n",
      "Epoch 8/10\n",
      "346/346 [==============================] - 3s 10ms/step\n",
      "Epoch 9/10\n",
      "346/346 [==============================] - 3s 10ms/step\n",
      "Epoch 10/10\n",
      "346/346 [==============================] - 3s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14004f2e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_auc',  # 监控验证集上的 loss\n",
    "#     patience=3,          # 如果连续 3 轮没有改善，就停止训练\n",
    "#     restore_best_weights=True  # 训练结束后恢复到最优模型\n",
    "# )\n",
    "loss_fn = UnifiedLTVLoss('mse')\n",
    "model.compile(loss=loss_fn, optimizer = 'adam')\n",
    "# 提前构造 input_shape\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,       # ✅ 这一步关键\n",
    "    profile_batch='5,10'    # ✅ 让 Profiler 在第5~10个 batch 才执行\n",
    ")\n",
    "model.fit(\n",
    "    create_tf_dataset(dataset),\n",
    "    epochs=10,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f72d1fb4-7413-421a-8415-818c3942faca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# 确保模型已构建，可以先跑一条样本\n",
    "sample = next(iter(dataset))\n",
    "model(sample)  # 让模型初始化权重和结构\n",
    "\n",
    "plot_model(model, to_file='model_structure.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ebc67ad-fd34-4f54-9058-24921880781c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 19:00:15.199199: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2025-06-19 19:00:15.199238: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2025-06-19 19:00:15.284858: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2025-06-19 19:00:15.298813: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2025-06-19 19:00:15.310071: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/plugins/profile/2025_06_19_19_00_15\n",
      "\n",
      "2025-06-19 19:00:15.311801: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/plugins/profile/2025_06_19_19_00_15/CK-L220022-2.local.trace.json.gz\n",
      "2025-06-19 19:00:15.312696: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/plugins/profile/2025_06_19_19_00_15\n",
      "\n",
      "2025-06-19 19:00:15.312851: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/plugins/profile/2025_06_19_19_00_15/CK-L220022-2.local.memory_profile.json.gz\n",
      "2025-06-19 19:00:15.313352: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/plugins/profile/2025_06_19_19_00_15\n",
      "Dumped tool data for xplane.pb to logs/plugins/profile/2025_06_19_19_00_15/CK-L220022-2.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/plugins/profile/2025_06_19_19_00_15/CK-L220022-2.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/plugins/profile/2025_06_19_19_00_15/CK-L220022-2.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/plugins/profile/2025_06_19_19_00_15/CK-L220022-2.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/plugins/profile/2025_06_19_19_00_15/CK-L220022-2.local.kernel_stats.pb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 1. 启动 profiler\n",
    "tf.profiler.experimental.start('logs')\n",
    "\n",
    "# 2. 跑一次模型（比如跑一个 batch）\n",
    "_ = model(sample)  # 你之前已经拿过 sample = next(iter(dataset))\n",
    "\n",
    "# 3. 停止 profiler\n",
    "tf.profiler.experimental.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88dd72cc-c94c-442b-8547-19c8c448767a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qiangpiao/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/qiangpiao/lib/python3.8/site-packages/keras/saving/save.py:142\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (save_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     (h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile)) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     saving_utils\u001b[38;5;241m.\u001b[39mis_hdf5_filepath(filepath)):\n\u001b[1;32m    139\u001b[0m   \u001b[38;5;66;03m# TODO(b/130258301): add utility method for detecting model type.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_is_graph_network \u001b[38;5;129;01mand\u001b[39;00m  \u001b[38;5;66;03m# pylint:disable=protected-access\u001b[39;00m\n\u001b[1;32m    141\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, sequential\u001b[38;5;241m.\u001b[39mSequential)):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaving the model to HDF5 format requires the model to be a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunctional model or a Sequential model. It does not work for \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubclassed models, because such models are defined via the body of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma Python method, which isn\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt safely serializable. Consider saving \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto the Tensorflow SavedModel format (by setting save_format=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mor using `save_weights`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    149\u001b[0m   hdf5_format\u001b[38;5;241m.\u001b[39msave_model_to_hdf5(\n\u001b[1;32m    150\u001b[0m       model, filepath, overwrite, include_optimizer)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`."
     ]
    }
   ],
   "source": [
    "model.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d856955-243f-47da-a588-c93cffedea9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是否包含 0: False\n",
      "tf.Tensor(\n",
      "[ 3.  1.  2.  1.  3.  2.  1.  5.  2.  3.  1.  4.  1.  2.  3.  3.  4.  4.\n",
      "  4.  3.  3.  2.  3.  3.  1.  2.  2.  4.  5.  3.  1.  4.  3.  2.  3.  2.\n",
      "  4.  4.  3.  2.  3.  5.  1.  4.  2.  1.  1.  2.  1.  4.  5.  2.  3.  1.\n",
      "  2.  1.  1.  3.  5.  4.  3.  5.  2.  5.  4.  1.  4.  5.  2.  3.  4.  3.\n",
      "  3.  3.  4.  3.  2.  5.  4.  2.  4.  4.  5.  4.  1.  1.  2.  4.  4.  2.\n",
      "  2.  5.  2.  2.  3.  4.  1.  2.  4.  3.  2.  4.  5.  2.  4.  5.  2.  2.\n",
      "  1.  3.  2.  3.  1.  5.  2.  5.  4.  2.  3.  4.  2.  3.  3.  5.  2.  4.\n",
      "  2.  3.  5.  5.  2.  1.  5.  3.  4.  2.  3.  3.  5.  1.  1.  4.  4.  3.\n",
      "  4.  2.  4.  3.  4.  5.  2.  2.  5.  3.  3.  1.  5.  5.  2.  3.  5.  3.\n",
      "  4.  2.  1.  1.  2.  1.  5.  5.  4.  2.  3.  1.  4.  5.  3.  4.  1.  4.\n",
      "  4.  3.  2.  5.  2.  3.  2.  1.  3.  5.  5.  4.  5.  1.  5.  4.  5.  2.\n",
      "  4.  4.  1.  5.  1.  2.  1.  3.  3.  3.  5.  3.  2.  4.  1.  2.  5.  1.\n",
      "  1.  4.  2.  4.  2.  2.  4.  1.  2.  4.  2.  3.  5.  1.  3.  1.  4.  4.\n",
      "  1.  4.  1.  2.  2.  4.  3.  1.  3.  1.  1.  5.  3.  5.  4.  5.  5.  4.\n",
      "  1.  5.  5.  4.  3.  3.  3.  5.  3.  2.  1.  5.  1.  2.  2.  2.  1.  1.\n",
      "  3.  2.  2.  5.  2.  5.  1.  2.  2.  4.  4.  4.  4.  1.  2.  1.  2.  2.\n",
      "  2.  4.  1.  2.  4.  4.  2.  2.  3.  2.  2.  1.  3.  2.  2.  5.  1.  2.\n",
      "  3.  3.  5.  1.  4.  3.  2.  4.  3.  4.  2.  1.  4.  4.  2.  1.  5.  5.\n",
      "  1.  2.  1.  4.  2.  3.  2.  4.  3.  4.  4.  4.  4.  2.  1.  1.  3.  2.\n",
      "  2.  4.  1.  4.  1.  2.  4.  3.  4.  4.  3.  4.  5.  3.  1.  4.  5.  1.\n",
      "  4.  4.  3.  4.  4.  2.  3.  2.  3.  4.  4.  4.  1.  2.  5.  1.  3.  1.\n",
      "  1.  1.  1.  2.  3.  2.  5.  2.  1.  2.  1.  4.  4.  5.  1.  1.  4.  1.\n",
      "  1.  1.  2.  5.  5.  4. 37.  1.  2.  2.  5.  2.  2.  2.  3.  4.  1.  5.\n",
      "  5.  1.  1.  3.  5.  2.  1.  1.  1.  4.  2.  2.  3.  1.  5.  4.  3.  1.\n",
      "  1.  5.  4.  4.  3.  5.  1.  2.  5.  3.  1.  4.  3.  4.  3.  2.  1.  5.\n",
      "  2.  4.  1.  1.  1.  1.  1.  3.  4.  1.  3.  4.  2.  1.  3.  5.  3.  4.\n",
      "  4.  3.  4.  1.  4.  3.  3.  1.  3.  5.  3.  4.  4.  4.  3.  5.  3.  3.\n",
      "  5.  2.  4.  3.  4.  1.  1.  3.  1.  5.  5.  4.  3.  4.  4.  2.  1.  5.\n",
      "  5.  5.  5.  1.  2.  1.  4.  4.], shape=(512,), dtype=float32)\n",
      "是否包含 0: False\n",
      "tf.Tensor(\n",
      "[3. 1. 1. 5. 4. 2. 5. 3. 2. 1. 4. 5. 2. 2. 4. 2. 5. 2. 5. 4. 3. 4. 4. 1.\n",
      " 5. 4. 5. 2. 2. 3. 3. 3. 4. 5. 1. 5. 3. 2. 2. 1. 5. 3. 4. 4. 3. 5. 3. 4.\n",
      " 3. 5. 1. 1. 3. 3. 1. 5. 1. 4. 1. 5. 1. 1. 1. 1. 2. 4. 5. 4. 3. 1. 1. 5.\n",
      " 4. 5. 3. 2. 3. 2. 1. 5. 5. 4. 5. 2. 1. 3. 5. 2. 4. 3. 1. 4. 4. 3. 5. 2.\n",
      " 4. 3. 1. 4. 5. 5. 2. 2. 1. 4. 3. 2. 5. 4. 5. 3. 3. 3. 4. 3. 1. 5. 2. 4.\n",
      " 5. 4. 5. 1. 5. 4. 2. 3. 4. 1. 1. 1. 1. 2. 5. 1. 3. 4. 1. 2. 1. 3. 1. 1.\n",
      " 1. 4. 5. 1. 4. 1. 4. 2. 1. 4. 1. 4. 5. 5. 3. 1. 5. 3. 2. 2. 2. 5. 5. 1.\n",
      " 2. 2. 5. 4. 3. 3. 4. 2. 2. 1. 5. 3. 5. 2. 5. 2. 5. 5. 3. 3. 1. 4. 3. 3.\n",
      " 4. 2. 3. 1. 4. 5. 3. 1. 3. 4. 2. 4. 3. 5. 5. 3. 2. 2. 4. 2. 5. 3. 1. 1.\n",
      " 3. 5. 5. 5. 5. 1. 3. 1. 5. 3. 1. 5. 1. 3. 4. 2. 2. 2. 5. 4. 1. 3. 4. 5.\n",
      " 3. 4. 1. 3. 4. 5. 3. 1. 3. 4. 2. 4. 4. 4. 2. 3. 4. 4. 3. 2. 3. 4. 2. 3.\n",
      " 3. 4. 3. 1. 5. 4. 2. 2. 4. 5. 1. 5. 3. 5. 1. 5. 1. 5. 2. 3. 1. 1. 3. 2.\n",
      " 5. 2. 5. 4. 3. 2. 1. 1. 2. 3. 3. 5. 5. 4. 3. 3. 3. 4. 5. 1. 3. 1. 5. 5.\n",
      " 5. 3. 3. 4. 2. 2. 3. 1. 5. 2. 5. 4. 5. 1. 2. 3. 5. 5. 5. 5. 3. 4. 4. 4.\n",
      " 2. 5. 4. 1. 3. 1. 3. 4. 2. 5. 3. 5. 4. 2. 4. 4. 5. 2. 1. 5. 1. 4. 1. 1.\n",
      " 3. 4. 4. 3. 1. 3. 1. 4. 4. 1. 5. 3. 4. 2. 4. 4. 5. 3. 2. 1. 3. 5. 3. 2.\n",
      " 5. 5. 4. 2. 5. 3. 3. 3. 1. 4. 1. 4. 3. 3. 5. 2. 3. 1. 2. 3. 3. 5. 4. 5.\n",
      " 3. 2. 1. 4. 3. 2. 4. 1. 1. 4. 3. 1. 3. 4. 3. 5. 5. 1. 5. 3. 3. 3. 5. 4.\n",
      " 1. 4. 3. 4. 2. 5. 5. 3. 1. 2. 3. 2. 3. 3. 5. 3. 2. 2. 2. 1. 5. 3. 1. 2.\n",
      " 2. 3. 4. 3. 1. 3. 5. 5. 5. 2. 2. 5. 3. 4. 2. 2. 1. 1. 1. 1. 2. 2. 3. 3.\n",
      " 1. 3. 3. 3. 3. 4. 1. 3. 3. 5. 1. 2. 1. 5. 5. 3. 4. 2. 4. 5. 1. 4. 2. 4.\n",
      " 4. 5. 4. 5. 1. 4. 4. 5.], shape=(512,), dtype=float32)\n",
      "是否包含 0: False\n",
      "tf.Tensor(\n",
      "[ 3.  4.  1.  3.  5.  1.  5.  4.  5.  4.  3.  1.  1.  3.  5.  5.  2.  5.\n",
      "  1.  1.  3.  5.  5.  5.  1.  5.  4.  5.  4.  3.  1.  3.  3.  2.  3.  3.\n",
      "  2.  5.  4.  4.  4.  4.  1.  1.  3.  4.  5.  3.  2.  5.  2.  1.  1. 12.\n",
      "  1.  4.  4.  3.  5.  1.  3.  3.  3.  1.  5.  5.  5.  2.  4.  3.  1.  2.\n",
      "  3.  2.  5.  1.  5.  1.  3.  5.  5.  2.  3.  1.  4.  5.  1.  2.  4.  5.\n",
      "  1.  2.  2.  2.  4.  5.  4.  5.  5.  5.  1.  4.  5.  1.  1.  1.  3.  2.\n",
      "  4.  4.  1.  2.  3.  3.  3.  5.  5.  1.  4.  5.  4.  4.  1.  3.  3.  4.\n",
      "  2.  3.  4.  1.  2.  5.  3.  5.  2.  3.  2.  2.  5.  3.  5.  5.  5.  3.\n",
      "  3.  1.  2.  4.  1.  1.  5.  4.  2.  2.  2.  1.  4.  5.  2.  2.  1.  4.\n",
      "  4.  5.  3.  5.  1.  5.  1.  5.  5.  3.  2.  3.  2.  2.  5.  3.  3.  3.\n",
      "  4.  3.  3.  3.  4.  2.  5.  4.  5.  5.  3.  4.  1.  1.  5.  5.  4.  5.\n",
      "  2.  4.  3.  4.  3.  3.  5.  2.  5.  5.  2.  5.  3.  4.  2.  4.  3.  3.\n",
      "  2.  3.  4.  4.  5.  1.  1.  5.  4.  1.  1.  4.  4.  3.  3.  5.  4.  1.\n",
      "  3.  2.  5.  3.  1.  1.  1.  5.  5.  1.  1.  4.  4.  3.  1.  3.  1.  2.\n",
      "  2.  4.  5.  1.  3.  2.  4.  3.  1.  1.  4.  2.  2.  1.  2.  4.  2.  2.\n",
      "  1.  3.  1.  2.  4.  1.  2.  5.  2.  4.  4.  4.  3.  3.  4.  4.  2.  5.\n",
      "  3.  2.  3.  5.  5.  3.  1.  3.  4.  3.  2.  5.  2.  2.  4.  2.  2.  1.\n",
      "  4.  2.  1.  1.  3.  2.  2.  5.  3.  5.  5.  3.  5.  5.  4.  2.  1.  5.\n",
      "  1.  5.  3.  5.  4.  5.  5.  4.  4.  1.  5.  4.  3.  3.  5.  5.  2.  4.\n",
      "  2.  2.  1.  2.  2.  3.  3.  2.  2.  4.  1.  2.  5.  1.  1.  5.  1.  1.\n",
      "  2.  2.  2.  3.  5.  5.  2.  1.  4.  5.  3.  4.  5.  1.  3.  2.  5.  3.\n",
      "  2.  2.  4.  1.  4.  2.  5.  4.  4.  4.  1.  1.  3.  1.  3.  2.  4.  2.\n",
      "  5.  4.  1.  3.  2.  2.  5.  5.  2.  5.  4.  4.  2.  3.  4.  3.  4.  2.\n",
      "  4.  5.  2.  5.  3.  3.  3.  2.  4.  4.  2.  3.  3.  2.  3.  4.  3.  5.\n",
      "  1.  5.  3.  4.  2.  5.  1.  1.  2.  3.  3.  5.  4.  2.  1.  4.  2.  1.\n",
      "  3.  3.  1.  2.  1.  5.  3.  5.  5.  2.  1.  4.  5.  5.  1.  3.  5.  5.\n",
      "  5.  4.  5.  5.  3.  4.  4.  5.  4.  1.  4.  2.  4.  1.  4.  4.  1.  1.\n",
      "  5.  5.  2.  5.  1.  3.  1.  4.  2.  5.  4.  3.  4.  5.  2.  5.  3.  5.\n",
      "  5.  2.  1. 11.  4.  4.  5.  5.], shape=(512,), dtype=float32)\n",
      "是否包含 0: False\n",
      "tf.Tensor(\n",
      "[5. 5. 2. 2. 5. 1. 1. 2. 2. 2. 2. 5. 5. 3. 2. 5. 5. 4. 4. 4. 4. 4. 3. 4.\n",
      " 3. 3. 2. 1. 2. 4. 2. 4. 3. 1. 5. 2. 3. 4. 4. 5. 3. 4. 3. 4. 2. 3. 3. 3.\n",
      " 1. 1. 2. 5. 1. 2. 4. 3. 2. 3. 2. 3. 2. 5. 1. 1. 5. 1. 1. 1. 1. 3. 2. 4.\n",
      " 1. 4. 5. 3. 1. 4. 4. 3. 2. 1. 3. 1. 5. 4. 1. 5. 1. 1. 3. 2. 5. 2. 1. 1.\n",
      " 4. 3. 1. 3. 3. 4. 4. 4. 1. 1. 2. 4. 5. 1. 5. 4. 2. 5. 1. 3. 1. 5. 5. 4.\n",
      " 2. 4. 1. 3. 1. 3. 1. 4. 4. 1. 2. 1. 4. 4. 1. 2. 4. 4. 5. 3. 4. 5. 5. 3.\n",
      " 5. 3. 2. 2. 1. 4. 4. 2. 1. 3. 2. 5. 1. 1. 1. 2. 2. 4. 5. 3. 4. 1. 1. 4.\n",
      " 5. 5. 1. 3. 4. 5. 1. 2. 5. 5. 3. 1. 5. 5. 5. 1. 2. 2. 5. 1. 4. 3. 5. 5.\n",
      " 3. 3. 1. 3. 3. 1. 5. 5. 4. 4. 4. 1. 5. 3. 3. 2. 5. 5. 5. 2. 5. 4. 1. 5.\n",
      " 5. 1. 5. 3. 3. 4. 3. 1. 4. 5. 2. 3. 1. 2. 1. 5. 3. 5. 1. 5. 5. 4. 3. 3.\n",
      " 4. 4. 5. 3. 1. 3. 3. 4. 1. 3. 2. 4. 3. 1. 2. 4. 4. 2. 2. 5. 4. 5. 2. 2.\n",
      " 4. 5. 1. 1. 1. 4. 5. 2. 1. 2. 1. 3. 5. 4. 5. 1. 3. 3. 3. 3. 1. 4. 2. 3.\n",
      " 3. 4. 4. 3. 4. 4. 5. 5. 2. 2. 4. 5. 5. 2. 2. 2. 4. 4. 3. 4. 4. 3. 3. 5.\n",
      " 5. 2. 2. 2. 3. 5. 4. 1. 4. 4. 5. 1. 2. 3. 1. 3. 4. 3. 4. 3. 2. 3. 5. 5.\n",
      " 3. 5. 5. 2. 2. 1. 4. 4. 1. 5. 4. 4. 3. 4. 2. 3. 5. 5. 1. 2. 4. 5. 1. 4.\n",
      " 4. 4. 5. 2. 3. 2. 2. 2. 1. 1. 2. 4. 5. 5. 4. 3. 4. 3. 3. 2. 2. 3. 1. 3.\n",
      " 4. 1. 5. 2. 5. 2. 3. 4. 4. 5. 5. 3. 4. 4. 5. 4. 4. 3. 5. 4. 3. 2. 5. 5.\n",
      " 1. 4. 1. 1. 2. 5. 5. 1. 4. 3. 4. 1. 4. 3. 1. 1. 5. 3. 3. 4. 1. 1. 3. 1.\n",
      " 2. 4. 2. 3. 4. 2. 5. 3. 2. 3. 3. 1. 3. 3. 1. 4. 2. 5. 2. 4. 2. 4. 3. 3.\n",
      " 3. 5. 1. 2. 3. 3. 4. 3. 4. 4. 4. 5. 4. 3. 1. 3. 3. 4. 3. 1. 5. 2. 3. 2.\n",
      " 4. 1. 3. 2. 5. 1. 1. 4. 3. 4. 1. 4. 2. 3. 3. 1. 2. 2. 2. 3. 3. 4. 5. 5.\n",
      " 2. 4. 4. 2. 1. 2. 2. 5.], shape=(512,), dtype=float32)\n",
      "是否包含 0: False\n",
      "tf.Tensor(\n",
      "[4. 5. 5. 2. 4. 1. 2. 1. 3. 1. 2. 4. 3. 1. 4. 3. 2. 5. 3. 2. 1. 4. 5. 1.\n",
      " 3. 2. 1. 1. 4. 4. 2. 5. 2. 1. 3. 4. 4. 3. 5. 3. 2. 3. 4. 3. 3. 2. 5. 3.\n",
      " 4. 5. 3. 3. 5. 4. 5. 4. 3. 1. 1. 3. 5. 5. 2. 2. 2. 5. 4. 5. 2. 2. 5. 5.\n",
      " 2. 2. 3. 5. 4. 5. 2. 1. 1. 4. 2. 2. 2. 2. 2. 3. 2. 4. 4. 5. 3. 1. 2. 1.\n",
      " 4. 5. 5. 5. 2. 2. 5. 4. 4. 2. 5. 4. 4. 5. 4. 4. 1. 1. 1. 5. 4. 4. 3. 2.\n",
      " 2. 2. 4. 1. 4. 3. 4. 4. 5. 5. 3. 3. 2. 4. 3. 3. 3. 2. 2. 2. 4. 5. 4. 4.\n",
      " 4. 4. 3. 3. 5. 5. 3. 3. 4. 3. 4. 4. 2. 2. 1. 1. 5. 5. 2. 5. 4. 2. 2. 1.\n",
      " 5. 5. 4. 2. 1. 2. 4. 3. 5. 1. 4. 1. 2. 3. 2. 2. 1. 4. 1. 5. 4. 5. 1. 4.\n",
      " 3. 4. 2. 4. 5. 1. 1. 3. 1. 3. 3. 2. 1. 4. 5. 1. 2. 3. 1. 1. 5. 2. 4. 4.\n",
      " 4. 1. 2. 4. 1. 3. 5. 2. 2. 1. 5. 1. 1. 1. 3. 4. 5. 5. 4. 3. 2. 5. 3. 5.\n",
      " 4. 3. 1. 5. 4. 1. 5. 1. 5. 2. 5. 1. 3. 5. 1. 4. 5. 2. 2. 4. 4. 5. 1. 2.\n",
      " 1. 5. 4. 5. 5. 1. 3. 4. 4. 2. 4. 5. 4. 3. 2. 2. 1. 3. 3. 1. 5. 1. 2. 3.\n",
      " 2. 1. 4. 1. 3. 5. 2. 5. 3. 5. 2. 2. 3. 2. 2. 3. 5. 4. 5. 1. 4. 5. 2. 4.\n",
      " 3. 4. 5. 2. 5. 4. 2. 2. 2. 2. 1. 4. 1. 4. 3. 5. 2. 4. 2. 4. 4. 5. 2. 2.\n",
      " 2. 1. 2. 2. 3. 2. 2. 2. 2. 1. 2. 3. 3. 5. 2. 4. 5. 1. 5. 1. 1. 4. 3. 1.\n",
      " 3. 4. 2. 5. 1. 1. 2. 4. 4. 2. 2. 2. 4. 2. 4. 5. 1. 1. 1. 1. 3. 4. 2. 2.\n",
      " 3. 1. 2. 3. 1. 2. 2. 5. 4. 4. 2. 4. 5. 5. 3. 5. 1. 2. 5. 2. 1. 3. 4. 1.\n",
      " 2. 4. 3. 2. 2. 1. 1. 2. 4. 2. 1. 2. 4. 5. 1. 4. 3. 3. 5. 3. 5. 5. 3. 4.\n",
      " 5. 4. 5. 3. 1. 5. 4. 2. 4. 3. 2. 5. 1. 2. 3. 4. 5. 1. 3. 2. 2. 1. 5. 2.\n",
      " 1. 4. 4. 3. 3. 4. 1. 1. 4. 2. 4. 2. 5. 2. 1. 5. 3. 5. 5. 5. 1. 1. 3. 5.\n",
      " 1. 1. 5. 2. 1. 1. 1. 1. 1. 2. 3. 4. 3. 5. 2. 5. 1. 2. 3. 5. 1. 4. 3. 2.\n",
      " 5. 3. 1. 3. 5. 4. 1. 1.], shape=(512,), dtype=float32)\n",
      "是否包含 0: True\n",
      "tf.Tensor(\n",
      "[ 4.  4.  4.  2.  4.  2.  5.  1.  4.  5.  4.  2.  1.  1.  4.  5.  1.  4.\n",
      "  3.  2.  4.  5.  5.  4.  4.  2.  5.  5.  5.  5.  3.  2.  3.  3.  2.  5.\n",
      "  2.  1.  3.  3.  2.  5.  1.  1.  2.  1.  1.  2.  3.  4.  1.  2.  4.  4.\n",
      "  3.  2.  1.  2.  5.  1.  5.  1.  3.  5.  4.  2.  1.  1.  3.  1.  3.  1.\n",
      "  2.  1.  2.  4.  2.  4.  5.  3.  2.  3.  1.  3.  3.  3.  1.  2.  2.  1.\n",
      "  2.  4.  5.  6.  4.  3.  5.  4.  2.  2.  2.  5.  5.  4.  5.  2. 10.  5.\n",
      "  2.  3.  1.  2.  1.  4.  3.  4.  3.  3.  2.  3.  4.  4.  4.  4.  2.  3.\n",
      "  2.  3.  2.  2.  1.  4.  5.  1.  4.  5.  1.  1.  1.  4.  2.  1.  2.  3.\n",
      "  3.  3.  2.  3.  5.  2.  3.  5.  2.  2.  5.  1.  4.  2.  3.  3.  5.  5.\n",
      "  3.  2.  5.  3.  3.  3.  1.  1.  3.  1.  2.  1.  4.  2.  2.  2.  1.  2.\n",
      "  3.  1.  2.  4.  2.  2.  3.  5.  2.  5.  1.  4.  5.  5.  5.  4.  1.  5.\n",
      "  4.  3.  1.  2.  2.  5.  4.  2.  5.  5.  3.  1.  3.  3.  5.  1.  4.  2.\n",
      "  3.  4.  1.  3.  5.  5.  2.  5.  4.  3.  3.  3.  2.  4.  1.  1.  4.  1.\n",
      "  5.  3.  2.  1.  5.  3.  3.  2.  2.  3.  3.  2.  1.  3.  3.  3.  3.  1.\n",
      "  5.  5.  4.  2.  1.  4.  1.  3.  5.  2.  4.  4.  5.  1.  1.  2.  1.  1.\n",
      "  5.  4.  4.  4.  2.  4.  1.  5.  1.  5.  5.  5.  2.  2.  1.  1.  1.  2.\n",
      "  1.  2.  2.  5.  1.  1.  1.  1.  1.  5.  3.  5.  5.  3.  3.  4.  5.  4.\n",
      "  4.  3.  4.  1.  2.  3.  4.  2.  4.  4.  5.  3.  4.  1.  4.  2.  3.  1.\n",
      "  5.  5.  1.  3.  4.  3.  1.  2.  4.  5.  1.  4.  3.  4.  1.  5.  1.  4.\n",
      "  5.  4.  3.  2.  4.  2.  2.  4.  5.  3.  2.  5.  2.  5.  3.  4.  4.  3.\n",
      "  3.  2.  3.  4.  5.  3.  3.  5.  5.  1.  4.  4.  2.  2.  3.  3.  3.  5.\n",
      "  1.  3.  4.  2.  1.  3.  3.  1.  5.  3.  4.  1.  4.  2.  1.  1.  2.  3.\n",
      "  2.  3.  5.  5.  4.  3.  5.  4.  5.  5.  5.  2.  3.  2.  1.  2.  5.  3.\n",
      "  1.  5.  3.  3.  5.  4.  2.  5.  2.  4.  1.  2.  3.  5.  2.  4.  2.  5.\n",
      "  2.  2.  3.  1.  3.  2.  1.  4.  2.  4.  2.  3.  3.  2.  2.  4.  4.  3.\n",
      "  4.  1.  3.  4.  3.  5.  2.  5.  5.  5.  1.  5.  2.  3.  1.  5.  5.  4.\n",
      "  2.  1.  5.  4.  1.  5.  5.  1.  5.  5.  1.  3.  5.  1.  5.  2.  5.  1.\n",
      "  2.  5.  5.  1.  2.  4.  4.  5.  4.  5.  2.  5.  4.  3.  3.  2. 15.  3.\n",
      "  3.  1.  4.  0.  3.  1.  1.  1.], shape=(512,), dtype=float32)\n",
      "是否包含 0: True\n",
      "tf.Tensor(\n",
      "[ 5.  1.  1.  3. 23.  4.  3.  4.  2.  5.  4.  3.  3.  1.  3.  2. 23.  2.\n",
      "  5.  2.  4.  4.  2.  4.  1.  5.  3.  1.  3.  4.  5.  4.  3.  1.  5.  3.\n",
      "  4.  3.  5.  5.  3.  4.  4.  2.  4.  1.  5.  4.  4.  1.  4.  4.  3.  2.\n",
      "  4.  2.  2.  1.  1.  5.  3.  4.  3.  3.  1.  3.  1.  3.  1.  4.  4.  2.\n",
      "  2.  3.  3.  1.  5.  4.  5.  3.  5.  2.  5.  1.  4.  5.  5.  4.  1.  1.\n",
      "  1.  3.  4.  1.  0.  3.  5.  5.  4.  3.  4.  3.  4.  3.  5.  1.  3.  3.\n",
      "  3.  4.  4.  4.  4.  1.  5.  5.  3.  1.  3.  1.  2.  1.  3.  3.  4.  5.\n",
      "  5.  5.  2.  3.  5.  1.  3.  1.  2.  1.  2.  5.  3.  4.  5.  1.  5.  5.\n",
      "  3.  4.  4.  3.  2.  4.  1.  4.  5.  5.  4.  1.  4.  4.  5.  1.  5.  4.\n",
      "  2.  1.  1.  3.  3.  3.  4.  4.  1.  1.  1.  1.  3.  5.  2.  4.  2.  3.\n",
      "  2.  3.  2.  3.  1.  3.  4.  3.  3.  1.  5.  5.  4.  4.  3.  5.  1.  2.\n",
      "  1.  2.  2.  2.  4.  3.  1.  1.  3.  2.  5.  3.  5.  2.  3.  1.  5.  5.\n",
      "  3.  1.  5.  2.  2.  2.  2.  4.  3.  1.  2.  5.  2.  5.  3.  2.  2.  4.\n",
      "  2.  3.  1.  2.  1.  5.  2.  3.  2.  5.  4.  5.  4.  2.  1.  4.  3.  1.\n",
      "  3.  1.  3.  1.  5.  2.  2.  5.  3.  5.  3.  3.  3.  3.  1.  4.  4.  3.\n",
      "  4.  1.  3.  4.  2.  1.  4.  5.  5.  4.  4.  3.  5.  1.  5.  5.  5.  5.\n",
      "  3.  4.  1.  2.  3.  1.  2.  2.  3.  5.  5.  2.  4.  5.  5.  5.  3.  2.\n",
      "  2.  1.  2.  4.  2.  3.  2.  3.  1.  3.  5.  5.  2.  3.  5.  1.  5.  4.\n",
      "  5.  3.  2.  1.  2.  2.  5.  1.  5.  1.  1.  4.  1.  3.  2.  3.  4.  1.\n",
      "  5.  1.  4.  2.  1.  5.  4.  2.  3.  2.  1.  5.  1.  4.  3.  3.  5.  3.\n",
      "  2.  1.  1.  3.  5.  4.  1.  2.  3.  5.  5.  4.  5.  4.  1.  1.  2.  5.\n",
      "  2.  3.  2.  3.  1.  2.  1.  4.  4.  2.  1.  1.  4.  4.  4.  4.  1.  1.\n",
      "  4.  5.  5.  2.  1.  5.  3.  4.  5.  2.  1.  3.  4.  5.  1.  5.  3.  5.\n",
      "  3.  5.  3.  2.  4.  1.  3.  5.  1.  3.  5.  1.  2.  2.  1.  4.  5.  5.\n",
      "  4.  5.  3.  1.  2.  5.  2.  2.  5.  2.  4.  2.  3.  5.  2.  1.  2.  4.\n",
      "  3.  5.  4.  3.  4.  2.  5.  4.  2.  1.  4.  1.  1.  4.  3.  3.  2.  1.\n",
      "  2.  1.  3.  1.  2.  5.  5.  3.  2.  5.  2.  4.  4.  5.  5.  1.  5.  3.\n",
      "  4.  3.  5.  4.  3.  1.  5.  2.  2.  5.  4.  2.  5.  3.  5.  2.  5.  2.\n",
      "  1.  5.  1.  2.  4.  2.  4.  2.], shape=(512,), dtype=float32)\n",
      "是否包含 0: False\n",
      "tf.Tensor(\n",
      "[2. 3. 4. 5. 4. 1. 2. 3. 5. 2. 3. 2. 3. 3. 4. 1. 4. 2. 3. 3. 4. 3. 1. 4.\n",
      " 4. 3. 1. 2. 5. 5. 2. 5. 2. 4. 3. 2. 4. 3. 1. 5. 5. 1. 1. 1. 2. 4. 4. 5.\n",
      " 4. 5. 2. 1. 2. 2. 5. 2. 5. 1. 5. 3. 1. 4. 4. 3. 1. 2. 2. 5. 4. 3. 2. 5.\n",
      " 2. 1. 3. 2. 5. 2. 1. 4. 3. 1. 4. 2. 4. 5. 2. 5. 5. 5. 2. 2. 2. 4. 1. 4.\n",
      " 2. 1. 2. 4. 1. 1. 1. 5. 5. 1. 1. 2. 4. 1. 1. 2. 3. 1. 3. 5. 4. 3. 5. 3.\n",
      " 1. 3. 2. 4. 1. 3. 4. 4. 3. 3. 4. 2. 2. 2. 4. 3. 1. 4. 2. 5. 3. 5. 4. 3.\n",
      " 5. 2. 2. 2. 1. 5. 4. 5. 3. 1. 2. 1. 5. 4. 2. 1. 3. 1. 1. 5. 5. 1. 1. 1.\n",
      " 2. 3. 4. 2. 4. 5. 3. 1. 4. 1. 2. 3. 2. 3. 3. 5. 4. 1. 4. 2. 3. 5. 5. 5.\n",
      " 1. 2. 5. 3. 3. 3. 3. 3. 2. 2. 3. 1. 5. 1. 3. 2. 5. 2. 1. 4. 5. 3. 4. 3.\n",
      " 5. 3. 5. 4. 2. 3. 4. 4. 2. 1. 2. 1. 3. 4. 4. 3. 2. 1. 4. 3. 1. 3. 4. 1.\n",
      " 4. 1. 4. 5. 5. 5. 3. 2. 3. 2. 2. 2. 2. 3. 5. 5. 3. 1. 2. 4. 3. 2. 2. 3.\n",
      " 2. 2. 5. 3. 1. 3. 1. 4. 1. 4. 5. 3. 2. 4. 4. 3. 4. 1. 2. 1. 5. 2. 4. 1.\n",
      " 4. 3. 5. 1. 1. 1. 4. 1. 1. 3. 5. 5. 1. 2. 3. 1. 2. 3. 2. 5. 2. 4. 1. 4.\n",
      " 2. 1. 1. 5. 5. 5. 3. 3. 5. 5. 3. 4. 4. 1. 2. 2. 4. 2. 4. 1. 1. 2. 5. 3.\n",
      " 3. 2. 1. 2. 1. 5. 5. 5. 5. 1. 1. 3. 2. 5. 1. 4. 5. 2. 5. 3. 5. 5. 2. 3.\n",
      " 3. 4. 4. 1. 1. 2. 1. 5. 3. 2. 3. 5. 2. 5. 5. 4. 4. 1. 4. 5. 4. 2. 2. 5.\n",
      " 1. 5. 1. 3. 4. 1. 1. 3. 5. 5. 5. 5. 3. 3. 4. 5. 4. 4. 5. 5. 1. 4. 2. 3.\n",
      " 3. 5. 4. 1. 5. 3. 2. 4. 2. 3. 3. 1. 3. 3. 1. 5. 2. 3. 3. 3. 3. 5. 5. 2.\n",
      " 3. 3. 2. 4. 1. 2. 5. 4. 4. 2. 1. 1. 3. 3. 5. 1. 3. 4. 1. 1. 2. 4. 1. 1.\n",
      " 5. 4. 5. 3. 5. 2. 4. 4. 2. 4. 2. 4. 3. 1. 4. 5. 1. 1. 4. 2. 2. 3. 2. 5.\n",
      " 1. 2. 1. 2. 5. 4. 5. 3. 3. 3. 1. 2. 3. 4. 2. 1. 2. 3. 1. 3. 1. 4. 4. 3.\n",
      " 1. 5. 1. 5. 2. 2. 4. 1.], shape=(512,), dtype=float32)\n",
      "是否包含 0: True\n",
      "tf.Tensor(\n",
      "[3. 1. 1. 2. 5. 5. 3. 2. 3. 2. 2. 1. 2. 5. 5. 1. 3. 1. 3. 2. 3. 3. 1. 5.\n",
      " 1. 3. 2. 2. 2. 3. 3. 2. 4. 1. 5. 2. 5. 5. 3. 1. 3. 5. 5. 3. 2. 1. 5. 1.\n",
      " 5. 1. 1. 4. 4. 4. 5. 2. 3. 5. 2. 1. 4. 2. 5. 4. 4. 5. 4. 3. 1. 2. 5. 1.\n",
      " 3. 3. 1. 3. 2. 5. 3. 5. 1. 3. 1. 1. 3. 2. 1. 5. 3. 4. 2. 2. 3. 1. 4. 2.\n",
      " 4. 5. 5. 3. 2. 2. 4. 3. 3. 4. 1. 3. 1. 3. 1. 1. 3. 5. 3. 3. 3. 2. 4. 2.\n",
      " 2. 2. 5. 3. 5. 5. 5. 5. 2. 1. 1. 4. 4. 3. 4. 5. 3. 5. 3. 1. 2. 1. 1. 1.\n",
      " 1. 1. 5. 3. 2. 4. 4. 2. 1. 2. 2. 4. 1. 3. 2. 4. 2. 1. 4. 2. 1. 3. 3. 1.\n",
      " 3. 2. 2. 2. 1. 4. 2. 5. 1. 4. 3. 2. 2. 3. 3. 1. 1. 5. 2. 5. 4. 3. 4. 2.\n",
      " 5. 5. 3. 3. 1. 4. 4. 2. 2. 4. 4. 1. 2. 4. 5. 2. 4. 2. 2. 2. 3. 2. 1. 3.\n",
      " 2. 4. 1. 5. 4. 2. 3. 1. 4. 3. 1. 5. 2. 3. 1. 5. 4. 2. 4. 5. 2. 2. 4. 4.\n",
      " 2. 2. 2. 3. 5. 3. 3. 2. 5. 5. 5. 4. 1. 3. 3. 2. 2. 5. 2. 5. 1. 4. 2. 1.\n",
      " 4. 3. 2. 4. 5. 2. 1. 5. 5. 5. 3. 3. 5. 2. 1. 2. 1. 1. 4. 3. 4. 5. 5. 5.\n",
      " 4. 4. 1. 4. 3. 5. 4. 4. 4. 4. 1. 5. 3. 4. 1. 1. 1. 4. 2. 4. 5. 1. 1. 2.\n",
      " 1. 2. 1. 3. 4. 3. 3. 2. 4. 3. 2. 3. 4. 1. 3. 5. 4. 1. 5. 2. 2. 1. 3. 5.\n",
      " 5. 4. 5. 3. 5. 3. 5. 3. 1. 4. 1. 5. 5. 0. 2. 3. 5. 4. 2. 1. 5. 5. 1. 1.\n",
      " 5. 3. 1. 1. 3. 5. 5. 5. 5. 1. 4. 3. 5. 1. 4. 2. 4. 5. 4. 4. 4. 4. 1. 5.\n",
      " 5. 2. 3. 5. 1. 2. 3. 5. 2. 2. 5. 2. 3. 5. 5. 5. 5. 3. 5. 1. 1. 1. 3. 2.\n",
      " 2. 3. 5. 3. 3. 1. 2. 3. 5. 1. 5. 2. 5. 4. 4. 4. 1. 3. 2. 3. 1. 1. 5. 1.\n",
      " 4. 4. 3. 3. 5. 5. 2. 3. 3. 4. 1. 3. 2. 5. 2. 1. 5. 5. 2. 3. 5. 2. 1. 1.\n",
      " 2. 4. 3. 2. 3. 2. 1. 4. 4. 2. 1. 2. 4. 1. 3. 3. 5. 1. 5. 5. 1. 1. 1. 2.\n",
      " 2. 4. 1. 4. 3. 1. 5. 1. 4. 4. 4. 1. 4. 4. 4. 4. 4. 5. 5. 2. 2. 1. 3. 1.\n",
      " 5. 2. 4. 1. 4. 1. 3. 5.], shape=(512,), dtype=float32)\n",
      "是否包含 0: False\n",
      "tf.Tensor(\n",
      "[ 3.  5.  2.  4.  3.  1.  2.  5.  2.  2.  2.  5.  1.  5.  2.  4.  2.  5.\n",
      "  4.  3.  5.  3.  1.  1.  2.  4.  2.  5.  2.  2.  4.  3.  5.  1.  3.  3.\n",
      "  2.  3.  2.  1.  2.  2.  1.  2.  2.  5.  4.  2.  3.  5.  4.  5.  2.  4.\n",
      "  4.  2.  1.  5.  3.  4.  1.  1.  4.  1.  2.  5.  5.  2.  1.  3.  5.  1.\n",
      "  1.  4.  1.  5.  2.  2.  5.  2.  3.  4.  4.  1.  1.  4.  4.  1.  3.  4.\n",
      "  3.  5.  2.  2.  2.  5.  2.  5.  4.  3.  5.  2.  1.  2.  1.  5.  1.  3.\n",
      "  1.  5.  2.  3.  3.  2.  3.  2.  5.  2.  4.  4.  2.  5.  1.  2.  2.  1.\n",
      "  1.  1.  1.  4.  1.  2.  1.  5.  1.  2.  1.  1.  1.  3.  3.  3.  5.  2.\n",
      "  5.  2.  5.  1.  1.  3.  5.  3.  5.  5.  5.  3.  4.  2.  1.  3.  5.  2.\n",
      "  5.  3.  3.  3.  1.  3.  4.  2.  2.  3.  5.  5.  1.  2.  3.  1.  4.  3.\n",
      "  1.  3.  1.  3.  5.  5.  5.  4.  1.  1.  2.  5.  5.  2.  5.  3.  5.  5.\n",
      "  2.  5.  3.  5.  3.  5.  4.  5.  5.  4.  1.  5.  3.  4.  3.  3.  5.  5.\n",
      "  2.  1.  2.  1.  5.  2.  1.  3.  2.  1.  5.  1.  3.  4.  4.  2.  2.  1.\n",
      "  1.  2.  3.  2.  1.  1.  3.  4.  3.  5.  2.  4.  5.  4.  5.  5.  3.  4.\n",
      "  1.  1.  2.  2.  4.  2.  2.  1.  4.  3.  5.  4.  3.  2.  4.  1.  1.  5.\n",
      "  1.  3.  2.  4.  2.  4.  2.  3.  2.  4.  2.  3.  2.  3.  4.  2.  4.  1.\n",
      "  2.  1.  3.  2.  3.  4.  3.  5.  5.  3.  3.  5.  1.  4.  3.  3.  4.  4.\n",
      "  4.  2.  1.  2.  4.  3.  1.  2.  2.  1.  3.  1.  1.  3.  1.  3.  2.  4.\n",
      "  5.  3.  4.  5.  3.  1.  5.  1.  1.  3.  5.  3.  2.  2.  3.  1.  4.  4.\n",
      "  1.  1.  5.  2.  5.  2.  3.  5.  4.  5.  4.  5.  2.  2.  4.  4.  5.  3.\n",
      "  5.  3.  5.  2.  1.  4.  5.  4.  2.  3.  3.  4.  5.  1.  1.  3.  5.  3.\n",
      "  1.  4.  3.  1.  3.  2.  4.  5.  2.  3.  1.  3.  2.  2.  5.  5.  1.  1.\n",
      "  4.  5.  1.  3.  5.  2.  2.  3.  1.  3.  1.  3.  5.  3.  2.  1.  2.  4.\n",
      "  1.  5.  2.  2.  1.  1.  1.  3.  4.  3.  4.  4.  2.  5.  2.  3.  2.  3.\n",
      "  3.  3.  4.  4.  4.  2.  3.  4.  2.  1.  4.  2.  3.  3.  2.  1.  2.  5.\n",
      "  2.  4.  5.  1.  4.  2.  4.  3.  2.  5.  4.  5.  3.  5.  4.  3.  5.  4.\n",
      "  4.  3.  3.  5.  3.  3.  3.  4. 23.  3.  1.  2.  1.  4.  1.  5.  1.  3.\n",
      "  1.  4.  4.  1.  1.  5.  5.  2.  5.  5.  2.  3.  1.  3.  5.  4.  5.  3.\n",
      "  2.  2.  3.  3.  3.  5.  4.  4.], shape=(512,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for batch in dataset.take(10):\n",
    "    # 示例 Tensor（比如从 batch 中某列提取出来的稀疏特征）\n",
    "    tensor = tf.gather(batch['user_sparse_features'], indices=0, axis=1)\n",
    "    # 判断是否含有 -1\n",
    "    contains_negative_one = tf.reduce_any(tf.equal(tensor,0))\n",
    "    # 打印结果（在 Eager 模式下，contains_negative_one 是一个布尔 Tensor）\n",
    "    print(\"是否包含 0:\", contains_negative_one.numpy())  # True 或 False\n",
    "    print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e0f27-96bc-4781-83aa-6998a8ba4169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
