{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0933135b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:14:21.965464Z",
     "start_time": "2025-06-24T08:14:18.922432Z"
    },
    "code_folding": [
     14
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 15:06:09.631343: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-27 15:06:09.810542: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-27 15:06:09.818046: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-06-27 15:06:09.818075: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-06-27 15:06:10.683732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-06-27 15:06:10.683812: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-06-27 15:06:10.683822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2025-06-27 15:06:12.528047: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2025-06-27 15:06:12.528089: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-06-27 15:06:12.528116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sh1-plf-ml-02): /proc/driver/nvidia/version does not exist\n",
      "2025-06-27 15:06:12.528778: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from models.model import *\n",
    "from ltv_utils import *\n",
    "from losses.custom_loss import *\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)  # 保留10位小数，可调整\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "\n",
    "\n",
    "def parse_function(serialized_example):\n",
    "    feature_description = {\n",
    "        'deviceid': tf.io.FixedLenFeature([], tf.string),\n",
    "        'install_date': tf.io.FixedLenFeature([], tf.string),\n",
    "        'dim_os_name1': tf.io.FixedLenFeature([], tf.string),\n",
    "        'creative_classify1': tf.io.FixedLenFeature([], tf.string),\n",
    "        'total_pay_amount1':  tf.io.FixedLenFeature([], tf.float32),\n",
    "         'channel1': tf.io.FixedLenFeature([], tf.string),\n",
    "        'b2_sale_amt_bias':  tf.io.FixedLenFeature([], tf.int64),\n",
    "         'b2_sale_amt_7d': tf.io.FixedLenFeature([], tf.int64),\n",
    "         'install_time': tf.io.FixedLenFeature([], tf.string),\n",
    "        'install_order_diff':  tf.io.FixedLenFeature([], tf.int64),\n",
    "        'all_install_order_7d_diff':  tf.io.FixedLenFeature([], tf.int64),\n",
    "        'is_a1x_a33':  tf.io.FixedLenFeature([], tf.int64),\n",
    "        'platform_label':  tf.io.FixedLenFeature([], tf.string),\n",
    "        'user_dense_price_features': tf.io.FixedLenFeature([len(group_2_features['user_dense_price_features'])], tf.float32),\n",
    "        'user_dense_duration_features': tf.io.FixedLenFeature([len(group_2_features['user_dense_duration_features'])], tf.float32),\n",
    "        'user_dense_features': tf.io.FixedLenFeature([len(group_2_features['user_dense_features'])], tf.float32),\n",
    "        'user_sparse_features': tf.io.FixedLenFeature([len(group_2_features['user_sparse_features'])], tf.float32)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "    return example\n",
    "\n",
    "\n",
    "# load tf records\n",
    "group_2_features = read_feature_json_config('features/feature_list.json')\n",
    "\n",
    "train_file_name = 'data/ltv_0522_0603_multi_window_model_train/part-r-00000'\n",
    "valid_file_name = 'data/ltv_0522_0603_multi_window_model_valid/part-r-00000'\n",
    "\n",
    "train_dataset, valid_dataset, _ = get_trian_valid_test_dateset(parse_function, 10240, train_file_name, valid_file_name)\n",
    "\n",
    "\n",
    "\n",
    "user_dense_price_features = group_2_features['user_dense_price_features']\n",
    "user_dense_duration_features = group_2_features['user_dense_duration_features']\n",
    "user_dense_features = group_2_features['user_dense_features']\n",
    "user_sparse_features = group_2_features['user_sparse_features']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063ab177-dbac-4ddc-9493-f1d8a4efb6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_HOUR = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7de35113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:14:23.991128Z",
     "start_time": "2025-06-24T08:14:23.973825Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_tf_dataset(dataset):\n",
    "    sample_batch = next(iter(dataset))\n",
    "    sample_data = {k: v for k, v in sample_batch.items() if k not in ['b2_sale_amt_7d', 'total_pay_amount1']}\n",
    "\n",
    "    \n",
    "    def generator():\n",
    "        for batch in dataset:\n",
    "            hour = tf.cast(tf.gather(batch['user_sparse_features'],  indices=0, axis = 1) - 1, tf.int64)    # shape: (batch_size,)\n",
    "            b2_7d = tf.cast(tf.reshape(batch.pop('b2_sale_amt_7d'), (-1, 1)), tf.float32)\n",
    "            # 将 b2_7d 中小于 0 的值替换为 0\n",
    "            b2_7d = tf.maximum(b2_7d, 0.0)\n",
    "            \n",
    "            total_amt_1h = tf.reshape(batch.pop('total_pay_amount1'), (-1, 1))\n",
    "\n",
    "            # 只保留 hour 为 MODEL_HOUR 的记录\n",
    "            # hour_mask = tf.equal(hour, MODEL_HOUR)  # shape: (batch_size,)\n",
    "            # hour_mask = tf.reshape(hour_mask, (-1, 1))  # 广播成 (batch_size, 1)\n",
    "            \n",
    "            # # # 使用 hour_mask 筛选 batch 中的 对应小时窗口 \n",
    "            # selected_indices = tf.where(hour_mask)[:, 0]  # 获取 hour == 1 的样本索引\n",
    "            # batch = {k: tf.gather(v, selected_indices, axis=0) for k, v in batch.items()}  # 筛选 batch 中的样本\n",
    "            # b2_7d = tf.gather(b2_7d, selected_indices, axis=0)  # 保留 hour == 1 对应的标签\n",
    "            # total_amt_1h = tf.gather(total_amt_1h, selected_indices, axis=0)  # 保留 hour == 1 对应的标签\n",
    "\n",
    "            # # 给某个小时 增加 真实值，测一下期望拟合\n",
    "            # hour_mask = tf.equal(hour, 4)  # shape: (batch_size,)\n",
    "            # hour_mask = tf.reshape(hour_mask, (-1, 1))  # 广播成 (batch_size, 1)\n",
    "            # # ✅ 对应位置加 10000\n",
    "            # b2_7d = tf.where(hour_mask, b2_7d + 10000.0, b2_7d)\n",
    "\n",
    "            \n",
    "    \n",
    "            # 将保留的样本和标签一起返回\n",
    "            y_true_packed = tf.concat([b2_7d, total_amt_1h], axis=1)\n",
    "\n",
    "            # y_true_packed = b2_7d\n",
    "            yield batch, y_true_packed\n",
    "        \n",
    "\n",
    "    # 正确写法：output_signature 中保留每个字段的真实 shape\n",
    "    output_signature = (\n",
    "        {\n",
    "            name: tf.TensorSpec(shape=(None,) + v.shape[1:], dtype=v.dtype)\n",
    "            for name, v in sample_data.items()\n",
    "        },\n",
    "        tf.TensorSpec(shape=(None, 2), dtype=tf.float32)\n",
    "    )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(generator, output_signature=output_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c54350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:14:25.021680Z",
     "start_time": "2025-06-24T08:14:24.757019Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "emb_features = [\n",
    "'creative_classify','dim_device_manufacture', 'car_add_type_most','show_order_is_2arrival_latest', 'selecttirecount_most', 'show_order_is_2arrival_most','selecttirecount_latest',\n",
    " 'new_sitename','advsite','car_add_type_latest','platform_level', 'tire_list_click_avg_index','tire_list_click_most_pid_level','tire_order_page_most_pid_level',\n",
    "]\n",
    "\n",
    "\n",
    "model = MULTI_HEAD_LTV_MODEL(5, [200], [200,128], 'user_dense_features', 'user_dense_price_features', 'user_dense_duration_features',\n",
    "                            'user_sparse_features',user_sparse_features, emb_features)\n",
    "\n",
    "\n",
    "sample = next(iter(train_dataset))\n",
    "input_shape = {k: v.shape for k, v in sample.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dc46ea8-b79a-4255-a767-9851ba5de99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自己实现的双口loss\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # 监控验证集上的 loss\n",
    "    patience=3,          # 如果连续 3 轮没有改善，就停止训练\n",
    "    restore_best_weights=True  # 训练结束后恢复到最优模型\n",
    ")\n",
    "\n",
    "loss_fn = UnifiedLTVLoss('delta')\n",
    "model.compile(loss=loss_fn, \n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005),  \n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49cdd2aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T07:49:36.643468Z",
     "start_time": "2025-06-24T07:48:03.904410Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext:15\", shape=(None, 2), dtype=float32)\n",
      "Tensor(\"IteratorGetNext:15\", shape=(None, 2), dtype=float32)\n",
      "277/277 [==============================] - 91s 306ms/step - rmse: 246.4369 - val_loss: 45690.2422 - val_rmse: 248.9426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8f9469e7c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    create_tf_dataset(train_dataset),\n",
    "    epochs=1,\n",
    "    validation_data = create_tf_dataset(valid_dataset),\n",
    "    callbacks= [early_stopping]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54981a6c-7889-4937-8c5d-4570695d66c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b73d02b-a23f-41df-98f0-a60997d9fe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 15:08:54.563228: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2025-06-27 15:08:54.563282: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2025-06-27 15:08:54.694572: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2025-06-27 15:08:54.710185: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2025-06-27 15:08:54.714613: I tensorflow/core/profiler/rpc/client/save_profile.cc:164] Collecting XSpace to repository: logs/plugins/profile/2025_06_27_15_08_54/sh1-plf-ml-02.xplane.pb\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# 确保模型已构建，可以先跑一条样本\n",
    "sample = next(iter(train_dataset))\n",
    "model(sample)  # 让模型初始化权重和结构\n",
    "\n",
    "# 1. 启动 profiler\n",
    "tf.profiler.experimental.start('logs')\n",
    "\n",
    "# 2. 跑一次模型（比如跑一个 batch）\n",
    "_ = model(sample)  # 你之前已经拿过 sample = next(iter(dataset))\n",
    "\n",
    "# 3. 停止 profiler\n",
    "tf.profiler.experimental.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1278a251-682e-49ed-9db1-cfc25b7d0b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_exp(create_tf_dataset(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af057d6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:15:15.701261Z",
     "start_time": "2025-06-24T08:15:00.659755Z"
    }
   },
   "outputs": [],
   "source": [
    "hour_model_pred = model.evaluate_rank(create_tf_dataset(valid_dataset))\n",
    "hour_model_pred"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b4d768a-3a44-4377-a562-914b0612718e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d730272-c195-4dfb-a59d-c6fb84538210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
